#summary Getting started guide for Java mapper library

== Adding the !MapReduce Library To Your Application ==

Checkout the mapreduce folder to a separate directory:

{{{
svn checkout http://appengine-mapreduce.googlecode.com/svn/trunk/java
}}}

Build the appropriate jar using ant in the directory you just checked out:

{{{
ant
}}}

Copy the resulting jars in the dist/lib directory into your application's WEB-INF/lib directory. If you're already using any of the dependency jars, there's no need to have duplicates.

Add the mapreduce handler to your app.xml:

{{{
<servlet>
  <servlet-name>mapreduce</servlet-name>
  <servlet-class>com.google.appengine.tools.mapreduce.MapReduceServlet</servlet-class>
</servlet>
<servlet-mapping>
  <servlet-name>mapreduce</servlet-name>
  <url-pattern>/mapreduce/*</url-pattern>
</servlet-mapping>
}}}

== Defining a Mapper ==

Create a class implementing !AppEngineMapper. You can see an example of such a class [http://code.google.com/p/appengine-mapreduce/source/browse/trunk/java/example/com/google/appengine/demos/mapreduce/TestMapper.java here].

There are two ways to start a mapper. You can either programmatically create a Configuration as seen [http://code.google.com/p/appengine-mapreduce/source/browse/trunk/java/example/com/google/appengine/demos/mapreduce/TestServlet.java here], or you can define a template using mapreduce.xml as seen [http://code.google.com/p/appengine-mapreduce/source/browse/trunk/java/example/war/WEB-INF/mapreduce.xml here]. There is a description of the mapreduce.xml format in the [http://code.google.com/p/appengine-mapreduce/source/browse/trunk/java/src/com/google/appengine/tools/mapreduce/ConfigurationTemplatePreprocessor.java javadoc for the ConfigurationTemplatePreprocessor class].

==Running the Mapper==

If you create a mapper using the configuration template approach, then you can start the mapper by navigating your browser to `http://<your_app_id>.appspot.com/mapreduce/status`
Click the launch button to start registered mapreduce. Go to the mapreduce detail page to observe its status and control its execution.

==Configuration Parameters==
You can set the following in your configuration to customize mapper behavior:

|| *key* || **default value** || **explanation** ||
|| mapreduce.mapper.inputprocessingrate || 1000 || The aggregate number of entities processed per second by all mappers. Used to prevent large amounts of quota being used up in a short time period. ||
|| mapreduce.mapper.shardcount || 8 || The number of concurrent workers to use. This also determines the number of shards to split the input into. ||

Additionally, each input format has its own configuration options:

There is currently only one input format: [http://code.google.com/p/appengine-mapreduce/source/browse/trunk/java/src/com/google/appengine/tools/mapreduce/DatastoreInputFormat.java DatastoreInputFormat]. Its options are:

|| *key* || **default value** || **explanation** ||
|| mapreduce.mapper.inputformat.datastoreinputformat.entitykind || None || The datastore entity to map over. ||


== Current Java Limitations ==
The following limitations apply to the current implementation. We're working to remove all of them:
  * Only full range scan is supported, i.e. it's impossible to scan some entity subset.
  * The entity to be mapped must have a descending index on __key__. There is support for guessing the key range in the Python implementation, and we plan to add that same strategy to the Java implementation.
  * Sharding is currently done by splitting the space of keys lexicographically. For instance, suppose you have the keys 'a', 'ab', 'ac', and 'e' and you request two splits. The framework will find that the first key is 'a' and the last key is 'e'. 'a' is the first letter and 'e' is the fifth, so the middle is 'c'. Therefore, the two splits are ['a'...'c') and ['c'...), with the first split containing 'a', 'ab', and 'ac', and the last split only containing 'e'.