#summary Getting started guide for python mapper library

== Adding !MapReduce Library To Your Application ==

Checkout the mapreduce folder into your application directory:

{{{
svn checkout http://appengine-mapreduce.googlecode.com/svn/trunk/python/src/mapreduce
}}}

Add the mapreduce handler to your app.yaml:

{{{
handlers:
- url: /mapreduce/.*
  script: mapreduce/main.py
  login: admin
}}}

== Defining a Mapper ==

Create a function with a single argument. It will be called for each entity fetched from the datastore:

{{{
def process(entity):
 # do something with entity here.
}}}

Register the mapper in mapreduce.yaml:

{{{
mapreduce:
- name: <Some descriptive name for UI>
  mapper:
    input_reader: mapreduce.DatastoreInputReader
    handler: <your handler name, e.g. main.process>
    params:
    - name: entity_kind
      default: <your entity name, e.g. main.MyEntity>
}}}

==Running the Mapper==

Navigate your browser to `http://<your_app_id>.appspot.com/mapreduce/`
Click the launch button to start registered mapreduce. Go to the mapreduce detail page to observe its status and control its execution.


==Modifying Datastore entities in the Mapper==
Mapper code can perform any kind of activity. But it's much more efficient to yield datastore mutation operations than to modify datastore directly:

{{{
from mapreduce import operation as op
def process(entity):
 # change entity
 yield op.db.Put(entity)
 # or yield op.db.Delete(entity)
}}}

All operations will be batched using a mutation pool. 

==Counters==

To change counter value yield a counter operation:

{{{
from mapreduce import operation as op
def process(entity):
 yield op.counter.Increment("counter1")
 yield op.counter.Increment("counter2", 30)
 yield op.counter.Increment("counter3", -5)
}}}

==Doing per-row “reduces”==

We don’t have the reduce capability yet, but you can approximate this if you have an Entity kind with a unique constraint on a particular filter. For example, say we had these entity kinds:

{{{
class UserKind(db.Model):
  # key_name is also the ldap
  ldap = db.StringProperty(required=True)
  last_week_attendance = db.IntegerProperty(default=0)

class ClassAttendance(db.Model):
  ldap = db.StringProperty(required=True)
  when = db.DateTimeProperty(required=True)
}}}

If you know you only have a single !UserKind per LDAP, then you can Map over the !UserKind and have a map function like this:

{{{
def find_attendance(user_entity):
  last_week = (
    datetime.datetime.now() -
    datetime.timedelta(days=7))
  count = (ClassAttendance.all()
      .filter('ldap =', user_entity.ldap)
      .filter('when >=', last_week)
      .count())
  user_entity.last_week_attendance = count
  yield op.db.Put(user_entity)
}}}

Currently we do not support transactions in the map function, so the Put operations yielded here will blindly overwrite any other data in the Datastore. For now it's best to be careful and stop live traffic from accessing these entities while a background job is running. We'll be adding transactions soon.


==Not Documented==

  * Shards count specification
  * Custom mapper parameters
  * Error handling
  * Blob readers

== Current Limitations ==

  * Only full range scan is supported, i.e. it's impossible to scan some entity subset